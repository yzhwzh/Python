{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.使用梯度下降求解\n",
    "$\\mathrm{L}=\\left(\\theta_{1}-3\\right)^{2}+\\left(2 \\theta_{2}-5\\right)^{2}$的最小值点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta1 , theta2 = 0.0,0.0\n",
    "alpha = 0.1\n",
    "for i in range(100):\n",
    "    theta1 = theta1 - alpha*2*(theta1-3)\n",
    "    theta2 = theta2 - alpha*2*(2*theta2 -5)*2\n",
    "    print(theta1,theta2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 使用梯度下降求解\n",
    "$\\mathrm{L}=\\left(\\theta_{1}-3\\right)^{2}\\left(2 \\theta_{2}-5\\right)^{2}$的最小值点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta1 , theta2 = 10.0,4.0\n",
    "alpha = 0.01\n",
    "for i in range(100):\n",
    "    theta1 = theta1 - alpha*2*(theta1-3)*(2*theta2-5)*(2*theta2-5)\n",
    "    theta2 = theta2 - alpha*2*(2*theta2 -5)*2*(theta1-3)*(theta1-3)\n",
    "    print(theta1,theta2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 使用梯度下降实现最小二乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearRegression(X,y,alpha,n_rounds):\n",
    "    n_features = X.shape[1]\n",
    "    beta = np.array([0.0]*n_features)\n",
    "    for i in range(n_rounds):\n",
    "        \n",
    "        #计算 epsilon\n",
    "        epsilon = y\n",
    "        for j in range(n_features):\n",
    "            epsilon = epsilon - beta[j]*X[:,j]\n",
    "            \n",
    "        #更新 beta\n",
    "        for j in range(n_features):\n",
    "            gradient = -np.mean(epsilon*X[:,j])\n",
    "            beta[j] = beta[j] - alpha*gradient\n",
    "\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确认实现的LinearRegression函数得到的结果与sklearn中的LinearRegression的结果相同\n",
    "data = pd.read_csv('height_train.csv')\n",
    "data['constant'] = 1\n",
    "LinearRegression(data.loc[:,['father_height','mother_height','boy_dummy','constant']].values,data.child_height.values,0.1,100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作业： 实现线性回归的代码，发布到各人Github\n",
    "\n",
    "选作：\n",
    "1. 收敛条件的判断\n",
    "2. 学习率的选择\n",
    "3. 类的形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
